<img src="./images/mainpage_figurev2.png" alt="Mainpage figure" style="width: 100% !important; max-width: none !important; display: block; margin: 0 auto;">

# The 1st MICCAI Workshop on Human-AI Collaboration (HAIC)

## Overview

The success of Artificial Intelligence (AI) in dynamic, real-world healthcare environments increasingly depends on effective collaboration between AI and human healthcare experts. Despite the rapid advancement of AI, significant questions remain regarding the role of human factors and the establishment of best practices for human-AI collaboration.  

**The 1st MICCAI Workshop on Human-AI Collaboration (HAIC)** offers the first systematic discussion forum addressing all aspects surrounding **human-AI interaction, collaboration, and human factor modeling** for the MICCAI community. Through this workshop, we aim to raise awareness about human-AI collaboration in MIC and CAI and spark discussions on identifying and addressing frequently overlooked challenges that involve human factors in MIC and CAI. 

The workshop will be held in conjunction with the [28th International Conference on Medical Image Computing and Computer Assisted Intervention](https://conferences.miccai.org/2025/en/default.asp) at Daejeon Convention Center, Daejeon, South Korea. 

## News

[August 11, 2025] We are honored to be sponsored by [NVIDIA](https://www.nvidia.com). ~~A GPU~~ An [**NVIDIA DGX Spark**](https://www.nvidia.com/en-gb/products/workstations/dgx-spark/), generously donated by NVIDIA, will be awarded to the Best Paper awardee!! A huge thanks to [#NVIDIA](https://www.nvidia.com/en-gb/) [#Prof. Stephen R. Aylward](https://www.aylward.org/), [#Dr. Daguaang Xu](https://research.nvidia.com/person/daguang-xu), and their teams.

[June 16, 2025] We have extended the submission deadline to July 02, 23:59 PST.

[May 19, 2025] The workshop is now [**open for submissions!**](https://cmt3.research.microsoft.com/HAIC2025) 

[April 3, 2025] Website for MICCAI HAIC workshop is online.

## Call for Papers

We call for original, unpublished works that cover innovative methodologies, validation, application, or best practices for human-AI interaction, collaboration, and human factor modeling in medical image computing and computer-assisted interventions. Please find it below a non-exhaustive list of themes and topics.

### List of Themes

**Human-AI collaborative approaches and joint decision making**

- Interactive predictors (e.g., interactive classification, detection, and segmentation)

- Joint decision approaches combining human expertise and AI insights
  
- Human-AI collaborative/assistive agents and agent systems

**Medical procedure analysis for human skill understanding and augmentation**
  
- Image/video analysis, interpretation, and action modeling for imaging and/or intervention procedures

- Human behavior modeling and analysis in medical procedures

- AI-assisted guidance and navigation for imaging and intervention

- AI-assisted medical text mining

- AI-accelerated medical science: hypothesis generation, experiment planning, implementation, and outcome interpretation

- Agents and agent systems inspired by human behaviors and specializations

**Emerging techniques for human-AI interaction and communication**

- Multimodal models that incorporate textual information (e.g., for medical question answering, diagnosis, and/or treatment planning)

- Incorporating human-friendly inputs: (e.g., natural language, audio, gesture, and gaze)

- Conversational models

- Patient-facing models

**Human-in-the-loop model training and fine-tuning**

- Interactive learning and fine-tuning approaches and applications

- Active learning approaches and applications

- Incorporating structured/unstructured human feedback (e.g., natural language instructions, preference labels) in training/fine-tuning

**Boosting transparency, interpretability, and risk management for joint human-AI systems**  

- Explainable medical AI and/or its impact on joint decisions

- Reasoning-empowered models

- Out-of-distribution management, hallucination mitigation, and decision deferrals

- Uncertainty modeling, propagation, and communication 

- Learning to safeguard AI and human users

**Interactive environments for clinical training, education, and human-AI teaming outcomes**

- AI assistants for medical education

- Simulation environments for clinical training and skill enhancement

- Virtual/augmented/mixed reality applications for HAIC

**Design and assessment for joint systems and workflows**

- Constructing new evaluation datasets  

- Identifying new clinically accepted evaluation metrics or gold standards

- Case study on existing human-AI joint workflows

**Applications: involving any of the above elements**

### Author Guidelines
**Format:** Submissions are required to follow the same [format](https://conferences.miccai.org/2025/en/PAPER-SUBMISSION-GUIDELINES.html) as specified for the MICCAI 2025 main conference: a maximum of 8 pages of main content, with up to 2 additional pages for references. All submissions should follow the Springer LNCS [LaTeX](https://conferences.miccai.org/2025/files/downloads/MICCAI2025-LaTeX-Template.zip) or [Word](https://conferences.miccai.org/2025/files/downloads/MICCAI2025-Word-Template.zip) template. 

**Review Process:** All submissions will undergo a double-blind peer-review process by multiple reviewers. 

**Presentations:** All accepted submissions will be invited for in-person poster presentations. A selected subset of works will be invited for oral or spotlight presentations. The decision on presentation format will be based on the reviewers' overall feedback and ranking. 

**Workshop Proceedings:**: 
Workshop proceedings with be published with the [Springer Lecture Notes in Computer Science (LNCS) series](https://www.springer.com/gp/computer-science/lncs). 


### Submission Guidelines

**Submission Portal:** Please submit your paper through the workshop's [CMT Portal](https://cmt3.research.microsoft.com/HAIC2025) (8-page + 2-page references, Springer LNCS format). 

**Submission Deadline:** July 2, 2025 (23:59 PST). 


## Program

### Keynote Speakers

[**Prof. Helen Higham**](https://www.neuroscience.ox.ac.uk/research-directory/helen-higham) (Director of the OxSTaR Centre, University of Oxford, UK)

[**Prof. Nassir Navab**](https://www.cs.cit.tum.de/camp/members/cv-nassir-navab/nassir-navab/) (Director of CAMP, Technical University of Munich, Germany)


### Industry Speaker

[**Dr. Daguang Xu**](https://research.nvidia.com/person/daguang-xu) (Senior Research Manager, NVIDIA)


### Program Schedule

Workshop Date: September 27, 2025

<br>

**Session 1:  Opening Remarks, Keynote 1, Industry Talk, and Oral Presentations**

13:30–13:40  Opening Remarks

<br>

13:40–14:05  Keynote Talk 1

*Prof. Helen Higham*, Director of the Oxford Simulation, Teaching and Research Centre (OxSTaR), University of Oxford

<br>
14:05–14:30  Industry Talk

*Dr. Daguang Xu*, Senior Research Manager, NVIDIA

<br>

14:30–15:30  Oral Session 1

14:30–14:45  User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents

*Andres Carvallo,  Denis Parra, Peter Brusilovsky, Hernan Valdivieso, Gabriel Rada, Ivania Donoso, Vladimir Araujo*

14:45–15:00  Explainable AI for Automated User-specific Feedback in Surgical Skill Acquisition

*Catalina Gomez, Lalithkumar Seenivasan, Xinrui Zou, Jeewoo Yoon, Sirui Chu, Ariel Leong, Patrick Kramer, Yu-Chun Ku, Jose L. Porras, Alejandro Martin-Gomez, Masaru Ishii, Mathias Unberath*

15:00–15:15  Beyond Manual Annotation: A Human-AI Collaborative Framework for Medical Image Segmentation Using Only “Better or Worse” Expert Feedback

*Yizhe Zhang*

15:15–15:30  A methodology for clinically driven interactive segmentation evaluation

*Parhom Esmaeili, Pedro Borges, Virginia Fernandez, Eli Gibson, Sebastien Ourselin, M.Jorge Cardoso*

15:30-16:00  Poster Session & Coffee Break

<br>

**Session 2: Keynote 2, Spotlight Presentations, Awards, and Concluding**

16:00–16:25  Keynote Talk 2

*Prof. Nassir Navab*, Director of the Laboratories for Computer Aided Medical Procedures, Technical University of Munich

<br>

16:25–17:00  Spotlight Talks

16:25–16:30  Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation

*Jingyun Yang, Guoqing Zhang, Jingge Wang, Yang Li*

16:30–16:35  Real-Time, Dynamic, and Highly Generalizable Ultrasound Image Simulation-Guided Procedure Training System for Musculoskeletal Minimally Invasive Treatment

*Xiandi Wang, Zekun Jiang, Mengqi Tang, Ying Han, Dan Pu, Kang Li*

16:35–16:40  Guided Active Learning for Medical Image Segmentation

*Bernhard Föllmer, Vladimir Serafimoski, Kenrick Schulze, Federico Biavati, Sebastian Stober, Wojciech Samek, Marc Dewey*

16:40–16:45  Simulating Inter-observer Variability Across Clinical Experience Levels

*Haley Gillett, Emma Stanley, Raissa Souza, Matthias Wilms, Nils Forkert*

16:45–16:50  Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays

*Denis Parra*

16:50–17:00  Q&A for Spotlight Talks

<br>

17:00–17:10  Awards and Concluding



## Important Dates
| Date  | Milestone |
|---|---|
| Submission open | April 15, 2025 |
| **Paper submission due** | **July 2, 2025** |
| Notification of paper decisions |	July 25, 2025 | 
|Camera-ready papers due	|	July 30, 2025 | 
|**Workshop date**	|		September 27, 2025 
<p align="right"><em>(All times are 23:59 PST)</em></p>


## Organizers
*Alphabetical order by last name*
### Organization Committee
- [Xiaoqing Guo](https://guo-xiaoqing.github.io/) (Hong Kong Baptist University) 

- [Yueming Jin](https://yuemingjin.github.io/) (National University of Singapore)

- [Hala Lamdouar](https://hlamdouar.github.io/) (University of Oxford)

- [Qianhui Men](https://qianhuimen.github.io/) (University of Bristol)

- [Cheng Ouyang](https://cheng-01037.github.io/) (University of Oxford)

- [Manish Sahu](https://sahumanish.github.io) (Johns Hopkins University)

- [S. Swaroop Vedula](https://malonecenter.jhu.edu/people/swaroop-vedula/) (Johns Hopkins University)

### Advisory Board

- [Qi Dou](http://www.cse.cuhk.edu.hk/~qdou/) (Chinese University of Hong Kong)

- [Helen Higham](http://www.cse.cuhk.edu.hk/~qdou/) (University of Oxford)

- [Nassir Navab](http://www.cse.cuhk.edu.hk/~qdou/) (Technical University of Munich)

- [Alison Noble](https://ibme.ox.ac.uk/person/alison-noble/) (University of Oxford)


### Program Committee

 - Alex Moehring (Purdue University)
 
 - Bernhard Kainz (FAU Erlangen-Nürnberg / Imperial College London) 

 - Caroline Essert (Université de Strasbourg / ICUBE)

 - David Black (University of British Columbia)
 
 - Francis Xiatian Zhang (University of Edinburgh) 
 
 - Haojun Jiang (Tsinghua University)
   
 - Harry Rogers (University of Oxford)

 - Hermione Warr (University of Oxford) 
  
 - Jiancheng Yang (EPFL)

 - Kun Yuan (University of Strasbourg)

 - Linlin Shen (Shenzhen University)

 - Mohammad Alsharid (Khalifa University)

 - Muhammad Ridzuan (MBZUAI)

 - Qian Li (National University of Singapore)

 - Qiaoyu Zheng (Shanghai Jiao Tong University)

 - Runlong He (University College London)

 - Ruoyu Chen (Institute of Information Engineering, Chinese Academy of Sciences)

 - Ryo Fujii (Keio University)

 - Yasin Ibrahim (University of Oxford)

 - Yunhe Gao (Rutgers University) 

 - Zhe Xu (Chinese University of Hong Kong)

 - Ziyang Wang (University of Oxford) 	

## Sponsors

<div style="margin-top: 20px; text-align: center;">
<img alt="nvidia-logo-horz" src="https://github.com/user-attachments/assets/58015356-04de-4131-b76e-d1a8e027f17f" width=385>
</div>  

## Awards

TBA

## Contact

For general inquiries please contact miccai.haic@gmail.com


<div style="margin-top: 20px; text-align: center;">
    <img src="/images/organizers_institutes.png" alt="Organizer's Institute Logo" style="max-width: 100%; height: auto;">
  </div>  

<style>
      a {
        color: #007785 !important;
      }
</style>
